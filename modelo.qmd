---
title: "Untitled"
controls: True
format: revealjs
editor: visual
---

```{r}
library(rstan)
library(readr)
library(dplyr)
library(ggdist)
library(ggplot2)
load("modelob0.RData")
```



## Regresión logística

::: {style="font-size: 87%;"}
Para modelar los diagnósticos, se plantea un modelo bayesiano de regresión logística. La variable respuesta es:

$$Y = \begin{cases}
1 \text{ si el paciente muestra deterioro cognitivo patológico} \\
0 \text{ en caso contrario}
\end{cases}$$

Donde: $\; \; \; \; \; \; \; \; Y_i|\pi_i \sim Bernoulli(\pi_i) \; \; \; \;$ y $\; \; \; \; E(Y_i) = \pi_i$

\

Entonces, para pasar a modelar una recta en vez de la variable dicotómica, se aplica la función *logit* como función de enlace.
:::

## Regresión logística

::: {style="font-size: 87%;"}
Por lo que la nueva variable a modelar será:

$$g(\pi_i)=\log\left( \frac{\pi_i}{1-\pi_i} \right) = \beta_0 + \beta_1 x_{1_i} + \beta_2 x_{2_i} + \dots$$ Entonces, se requiere plantear cuáles son las variables que ayudan a explicar la probabilidad de que una persona muestre deterioro cognitivo patológico. Para ello, primero se decide plantear modelos univariados para cada variable, y quedarse con aquellas donde el intervalo de credibilidad a *posteriori* del párametro no cubra el cero.
:::

## Definición de *priors*

::: {style="font-size: 87%;"}
Al no tener mucha información sobre el tema, se decide plantear para todos los paremetros  distribuciones a *priori* abarcativas, simetricas al 0 donde se le da un mayor peso al no efecto. La distribución que se usa y cumple dichos criterios es: $\; \; \;\beta_j \sim N(0,1) \ \ \forall j=\overline{0,9}$
:::

```{r, fig.align='center'}
datan = data.frame(y = dnorm(seq(-3,3,.1)), x = seq(-3,3,.1))
ggplot(datan) + geom_line(aes(x = x , y = y)) + labs(x = "Parametro", y = "Densidad", caption=" asd") + scale_x_continuous(breaks = -2:2)
```


## PP priori

Se escalan todas las variables continuas y se grafica la probabildad a priori de tener una enfermedad neurodegenerativa del modelo completo para los valores promedios de las variables cuantitativas.

```{r, fig.align='center'}
set.seed(123)
y0 = exp(rnorm(1000))
y1 = exp(rnorm(1000) + rnorm(1000))
y2 = exp(rnorm(1000) + rnorm(1000) + rnorm(1000))
y3 = exp(rnorm(1000) + rnorm(1000) + rnorm(1000) + rnorm(1000))

ye0 = y0/(y0+1)
ye1 = y1/(y1+1)
ye2 = y2/(y2+1)
ye3 = y3/(y3+1)


suma = data.frame(ye = c(quantile(ye0,.025),quantile(ye0,.975),quantile(ye1,.025),quantile(ye1,.975),quantile(ye2,.025),quantile(ye2,.975),quantile(ye3,.025),quantile(ye3,.975)), re= rep(0:3,each = 2) )

a = data.frame(x = c(median(ye0),median(ye1),median(ye2),median(ye3)))
a$cual = c("as", "S = Masculino\nI=1.5T\nR=GE", "S = Femenino\nI=3T\nR=GE","S = Femenino\nI=1.5T\nR=Philips")
ggplot(a) + geom_bar(aes(x = cual, y = x), stat = "identity", fill = "#5aeeac") + labs(x = "Nivel", y = expression(hat(pi))) + geom_point(aes(x = cual, y = x), color = "#047e46")+ scale_y_continuous(limits = c(0, 1)) + geom_line(data = suma, aes(y = ye, x = re+1, group = re), color = "#047e46") + scale_x_discrete(labels = c(expression(beta[0]), expression(beta[0]+beta["S"]), expression(beta[0]+beta["I"]+beta["S"]), expression(beta[0]+beta["R"]+beta["I"]+beta["S"]))) + theme(text = element_text(size = 15))
```
## PP priori

Bajo la distribución propuesta, los posibles valores de la probabilidad de tener una enfermedad neurodegenerativa a traves del cambio de una variable cuantitativa es:

```{r}
set.seed(231)
seq.cont = seq(-3,3,length.out = 71)
data_ppp = as.data.frame(matrix(nrow = 142*500, ncol = 3))

b0ppp = rnorm(500)
b1ppp = rnorm(500)
for (i in 1:500) {
  data_ppp[((i-1)*71+1):(71*i),] = data.frame(pi = rep(b0ppp[i], 71) + b1ppp[i] * seq.cont, grupo = rep(i,each = 71), cont = rep(seq.cont,1))
}



ggplot(data_ppp) + stat_lineribbon(aes(x = V3, y = exp(V1)/(1+exp(V1)), fill = V2, fill_ramp = after_stat(level)), fill = c("#168168"), alpha = .8) + theme(legend.position = "none") + labs(x = "Variable cuantitativa", y = expression(hat(pi)))

```



## PP priori

Una vez ajustados los modelos marginales, se ven las distribuciones a *posteriori* de los coeficientes asociados a cada variable.
```{r, fig.align='center'}
#| fig.cap:  $\textit{Posteriors}$ de los parametros para cada modelo univariado
load("reglin.RData")
reglogplot
```


## Titulo

Luego, se plantea un modelo con todas las variables con coeficientes asociados distintos de 0 y se prueba si aportan a la explicación de la probabilidad de tener una enfermedad neurodegenerativa al estar las demas presentes.


```{r, fig.align='center'}
reglogplot1
```


## Comparaciones entre modelos

Entonces, se comparan los ELPPD de distintos modelos propuestos con el que tiene VHI y ECSF. 


```{r}
load("ic_comp.RData")
ic_comp + theme_minimal()
```


## Ajuste y evaluación del modelo

El modelo final es el siguiente:

$$g(\pi_i)= \beta_0 + \beta_1 VHI_i  + \beta_2 ECSF_i $$ 

Una vez, ajustado el modelo se realiza la evaluación de las cadenas generados por HMC.

## Ajuste y evaluación del modelo

Las cadenas generadas fueron las siguientes:

```{r, fig.align='center'}

```

Todas tienen un $\hat{R}=1$, por lo que las distintas cadenas convergen a la misma distribución. Además, las trazas para cada cadena parece seguir un orden aleatorio por lo que se considera que la muestra extraída es representativa de la distribución del *posterior*.


## Distribucines a posteriori de los parametros

Una vez ajustado el modelo, se obtienen las siguientes distribuciones a *posteriori* para las escalas anteriores a la estandarización.

```{r}
posterior
```


## Pruebas predictivas a posteriori

## Modelo 2


::: {style="font-size: 87%;"}


Al ver que el efecto de las variables tecnológicas cubren al 0 para su intervalo de credibilidad, se piensan como un efecto despreciable, por lo que se plantea un modelo sin ellas.

$$Y^*_i= \beta_0 + \beta_1 VHI_i + \beta_2 VI_i + \beta_3 ECSF_i + \beta_4 VCF_i +$$ $$\beta_5 Sexo_i + \beta_6 Edad_i$$
:::

Entonces, utilizando los mismos *priors*, se procede a obtener las distribuciones a posteriori de los parámetros.


## Evaluación del modelo

Las cadenas generadas fueron las siguientes:

```{r, eval=FALSE}
modelob0 %>% 
  setNames(c("Beta 0", "Beta 1", "Beta 2", "Beta 3", "Beta 4", "Beta 5", "Beta 6")) %>%   
  traceplot(pars = c("b0", "b1", "b2", "b3", "b4", "b5", "b6")) + labs(colour = "Cadenas")
```

## Evaluación del modelo

Todas tienen un $\hat{R}=1$, por lo que las distintas cadenas convergen a la misma distribución. Además, las trazas para cada cadena parece seguir un orden aleatorio por lo que se considera que la muestra extraída es representativa de la distribución del *posterior*.

## Evaluación del modelo

Algunas medidas de las muestras extraídas son:


## Distribucines a posteriori de los parametros

Una vez ajustado el modelo, se obtienen las siguientes distribuciones a *posteriori*.


## Pruebas predictivas a posteriori
